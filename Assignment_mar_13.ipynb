{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71703144-cfc4-4e01-a0a2-49be8de74f25",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827c1ea-8710-4767-9c85-10a9cf0cdd30",
   "metadata": {},
   "source": [
    "### Ans1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2394e-c69f-4a20-b9ad-09588b018146",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique that is used to test for differences among two or more groups or samples. However, before conducting ANOVA, certain assumptions must be met in order to ensure that the results are valid and accurate. These assumptions include:\n",
    "\n",
    "1) Independence: The data within each group must be independent of each other. This means that there should be no relationship between the observations in one group and the observations in another group.\n",
    "\n",
    "2) Normality: The distribution of data within each group should be normal or approximately normal. This assumption is particularly important when the sample size is small.\n",
    "\n",
    "3) Homogeneity of variance: The variance of the data within each group should be equal or approximately equal. This assumption is important because if the variance is not equal, the test may not accurately reflect the differences among the groups.\n",
    "\n",
    "4) Random sampling: The samples should be randomly selected from the population.\n",
    "\n",
    "Violations of these assumptions can affect the validity of the ANOVA results. Examples of violations and their impact on validity are:\n",
    "\n",
    "1) Non-independence: If the data within one group is related to the data in another group, this can lead to bias in the results. For example, if a study is conducted in a classroom where students are grouped based on their academic ability, the data within each group may not be independent.\n",
    "\n",
    "2) Non-normality: If the distribution of the data is not normal, this can lead to inaccurate results. For example, if a sample is too small, the distribution may not appear to be normal, even if it is.\n",
    "\n",
    "3) Non-homogeneity of variance: If the variance of the data is not equal, the ANOVA may incorrectly detect significant differences among the groups. For example, if one group has a much larger variance than the others, this can lead to incorrect conclusions.\n",
    "\n",
    "4) Non-random sampling: If the samples are not randomly selected from the population, the results may not accurately reflect the population as a whole. For example, if a study is conducted only on people who volunteer, the results may not be representative of the entire population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167c7b7-0617-4e9c-b901-42aed1d82626",
   "metadata": {},
   "source": [
    "### Ans2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551329cc-5c11-4162-a96e-303b0589756c",
   "metadata": {},
   "source": [
    "The three types of ANOVA are:\n",
    "\n",
    "1) One-Way ANOVA: One-way ANOVA is used when there is only one independent variable, which has three or more levels (or categories). It is used to determine whether there are significant differences in the means of a dependent variable across the different levels of the independent variable. One-way ANOVA is commonly used in studies that involve comparing the means of several groups, such as in medical studies to compare the effectiveness of different treatments.\n",
    "\n",
    "2) Two-Way ANOVA: Two-way ANOVA is used when there are two independent variables. It is used to determine whether there are significant main effects of each independent variable and whether there is an interaction effect between the two independent variables on the dependent variable. Two-way ANOVA is commonly used in studies that involve examining the effects of two different factors, such as in psychology studies to examine the effects of both gender and age on a dependent variable.\n",
    "\n",
    "3) Three-Way ANOVA: Three-way ANOVA is used when there are three independent variables. It is used to determine whether there are significant main effects of each independent variable and whether there are interaction effects between each pair of independent variables, as well as a three-way interaction effect. Three-way ANOVA is commonly used in studies that involve examining the effects of three different factors, such as in education studies to examine the effects of teaching method, classroom size, and teacher experience on a dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192760ad-d85b-4dd8-98ad-0f1a74e428eb",
   "metadata": {},
   "source": [
    "### Ans3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946f2d5-155a-4ccd-aaf8-ce5d49e903a2",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA (Analysis of Variance) is a technique used to identify the sources of variation in a set of data. ANOVA is a statistical method that is used to compare the means of two or more groups and determine whether they are statistically significant.\n",
    "\n",
    "The variance of a set of data measures how much the data points are spread out from the mean. The partitioning of variance in ANOVA involves breaking down the total variance of the data into different components that can be attributed to specific sources of variation. These sources of variation can include differences between groups, differences within groups, and random error.\n",
    "\n",
    "Understanding the partitioning of variance in ANOVA is important because it allows researchers to identify the sources of variation in their data and determine which factors are contributing the most to differences between groups. By identifying these sources of variation, researchers can develop more accurate models to explain the data, make more precise predictions, and better understand the underlying processes that are driving the observed differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b84725-75eb-43b8-88f2-e3b9cb83d9d1",
   "metadata": {},
   "source": [
    "### Ans4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d61748-e951-49bf-989c-a25b36941cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST = 764.9041326290013\n",
      "SSE = 15.487573431470548\n",
      "SSR = 749.4165591975308\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Generate some sample data\n",
    "group1 = np.random.normal(loc=10, scale=2, size=30)\n",
    "group2 = np.random.normal(loc=12, scale=2, size=30)\n",
    "group3 = np.random.normal(loc=15, scale=2, size=30)\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the ANOVA\n",
    "f_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
    "n = len(data)\n",
    "k = 3\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "SST = np.sum((data - np.mean(data))**2)\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "SSE = np.sum((np.mean(group1) - np.mean(data))**2) + \\\n",
    "      np.sum((np.mean(group2) - np.mean(data))**2) + \\\n",
    "      np.sum((np.mean(group3) - np.mean(data))**2)\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"SST =\", SST)\n",
    "print(\"SSE =\", SSE)\n",
    "print(\"SSR =\", SSR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fdd717-7f10-4192-87eb-6cbb8a18b667",
   "metadata": {},
   "source": [
    "### Ans5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "385e8280-d7dc-4441-ab56-503302c3e7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effect of A: 0.09589041095890422\n",
      "Main effect of B: 0.3307240704500982\n",
      "Interaction effect: 0.001956947162426608\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create some sample data\n",
    "df = pd.DataFrame({'A': ['a1', 'a2', 'a1', 'a2', 'a1', 'a2', 'a1', 'a2'],\n",
    "                   'B': ['b1', 'b1', 'b2', 'b2', 'b1', 'b1', 'b2', 'b2'],\n",
    "                   'Y': [3, 4, 6, 8, 7, 9, 10, 12]})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Y ~ A + B + A:B', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the main effects and interaction effects\n",
    "main_effect_A = anova_table.loc['A', 'sum_sq'] / anova_table['sum_sq'].sum()\n",
    "main_effect_B = anova_table.loc['B', 'sum_sq'] / anova_table['sum_sq'].sum()\n",
    "interaction_effect = anova_table.loc['A:B', 'sum_sq'] / anova_table['sum_sq'].sum()\n",
    "\n",
    "print(\"Main effect of A:\", main_effect_A)\n",
    "print(\"Main effect of B:\", main_effect_B)\n",
    "print(\"Interaction effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ab50c1-c8c9-41f7-b089-df0efa79b2a0",
   "metadata": {},
   "source": [
    "### Ans6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92d704f-6328-4933-ae1f-e11a9130963a",
   "metadata": {},
   "source": [
    "If you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, you can conclude that there is at least one significant difference between the groups. The F-statistic indicates the ratio of the between-group variability to the within-group variability, and a larger F-statistic implies greater differences between the groups relative to the variation within each group. The p-value indicates the probability of obtaining an F-statistic as extreme as the one observed, assuming that there are no differences between the groups (i.e., the null hypothesis is true).\n",
    "\n",
    "A p-value of 0.02 indicates that there is strong evidence against the null hypothesis and suggests that the observed differences between the groups are unlikely to be due to chance alone. Typically, a p-value threshold of 0.05 is used to determine statistical significance, which means that if the p-value is less than 0.05, the differences between the groups are considered statistically significant.\n",
    "\n",
    "Therefore, in this case, you can conclude that there is strong evidence that at least one group is different from the others. However, you would need to conduct additional post-hoc tests or examine the confidence intervals of the group means to determine which specific group(s) differ significantly from each other.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c908a-6000-400b-b2e6-96c5f6782227",
   "metadata": {},
   "source": [
    "### Ans7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff3c0be-a3aa-42c0-96d7-2966a747dca6",
   "metadata": {},
   "source": [
    "Handling missing data in repeated measures ANOVA depends on the nature of the missing data. Here are a few potential methods for handling missing data in repeated measures ANOVA:\n",
    "\n",
    "1) Pairwise deletion: With this method, missing data are excluded from the analysis. However, this can lead to a loss of power and bias if the missing data are not missing at random (MAR).\n",
    "\n",
    "2) Last observation carried forward (LOCF): This method replaces missing values with the value from the previous time point. LOCF can introduce bias if the missing data are not missing at random.\n",
    "\n",
    "3) Maximum likelihood estimation: This is a statistical method that can be used to estimate missing data by assuming a specific distribution for the data. Maximum likelihood estimation can provide unbiased estimates if the data are missing at random.\n",
    "\n",
    "4) Multiple imputation: This method involves creating multiple plausible values for each missing data point based on the observed data and using these imputed values to estimate the model parameters. Multiple imputation can provide unbiased estimates if the data are missing at random, and it can also increase the precision of the estimates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca7f97-3b75-4b6f-b579-616ac9524818",
   "metadata": {},
   "source": [
    "### Ans8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae14c88-ae4a-49c9-853d-c144de96f715",
   "metadata": {},
   "source": [
    "Some common post-hoc tests include:\n",
    "\n",
    "1) Tukey's Honestly Significant Difference (HSD): This test is commonly used when there are three or more groups being compared. The Tukey HSD test calculates the minimum difference that must exist between the means of any two groups in order for that difference to be considered statistically significant.\n",
    "\n",
    "2) Bonferroni correction: This test adjusts the p-values of the pairwise comparisons to account for multiple comparisons, and is generally more conservative than other post-hoc tests. The Bonferroni correction can be used in situations where there are a large number of pairwise comparisons.\n",
    "\n",
    "3) Scheff√©'s test: This test is more conservative than Tukey's HSD test, and is used when there are a small number of groups being compared.\n",
    "\n",
    "4) Dunnett's test: This test is used when there is a control group being compared to multiple other groups. It controls the overall error rate while allowing for multiple pairwise comparisons with the control group.\n",
    "\n",
    "5) Fisher's Least Significant Difference (LSD): This test is used when there are only two groups being compared, and is less conservative than other post-hoc tests.\n",
    "\n",
    "An example of a situation where a post-hoc test might be necessary is in a study examining the effects of three different exercise programs on weight loss. After conducting an ANOVA, the researcher finds a significant difference between the means of the three groups. To determine which specific groups are significantly different from each other, the researcher could conduct a post-hoc test such as Tukey's HSD test. This would allow the researcher to identify which exercise programs resulted in significantly greater weight loss compared to the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc2921-2176-4c18-ba37-277431a86d43",
   "metadata": {},
   "source": [
    "### Ans9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c96ecd-7981-4d6b-9354-51ee01c50317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic:  177.87661148829076\n",
      "p-value:  3.1279147100109306e-25\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Define the data for each diet group\n",
    "diet_A = [5.1, 4.5, 6.2, 7.8, 3.2, 5.5, 4.3, 6.4, 4.9, 5.7, 6.1, 5.4, 4.7, 3.9, 5.3, 6.8, 5.6, 4.1, 5.9, 6.0]\n",
    "diet_B = [7.2, 8.5, 6.8, 7.5, 6.2, 8.1, 9.2, 7.8, 6.5, 7.0, 8.0, 7.3, 6.9, 8.3, 7.6, 6.7, 7.1, 7.9, 8.6, 6.4]\n",
    "diet_C = [10.3, 11.2, 12.1, 9.7, 11.0, 10.5, 12.6, 9.5, 10.8, 11.5, 9.9, 10.7, 11.4, 12.2, 10.6, 12.5, 11.9, 9.8, 10.4, 12.0]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic: \", f_statistic)\n",
    "print(\"p-value: \", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9c6548-176a-4c5d-9217-cbafa8d59ee2",
   "metadata": {},
   "source": [
    "### Ans10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66fe50ad-0544-497f-ac86-07df8d8f6bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(Software)</th>\n",
       "      <td>59.890667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>89.701448</td>\n",
       "      <td>7.281977e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(Experience)</th>\n",
       "      <td>6.075000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.197703</td>\n",
       "      <td>2.686055e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(Software):C(Experience)</th>\n",
       "      <td>0.216000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.323515</td>\n",
       "      <td>7.267079e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>8.012000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sum_sq    df          F        PR(>F)\n",
       "C(Software)                59.890667   2.0  89.701448  7.281977e-12\n",
       "C(Experience)               6.075000   1.0  18.197703  2.686055e-04\n",
       "C(Software):C(Experience)   0.216000   2.0   0.323515  7.267079e-01\n",
       "Residual                    8.012000  24.0        NaN           NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a data frame with the data\n",
    "data = {'Software': ['A', 'A', 'B', 'B', 'C', 'C', 'A', 'A', 'B', 'B', 'C', 'C',\n",
    "                     'A', 'A', 'B', 'B', 'C', 'C', 'A', 'A', 'B', 'B', 'C', 'C',\n",
    "                     'A', 'A', 'B', 'B', 'C', 'C'],\n",
    "        'Experience': ['Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced',\n",
    "                       'Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced',\n",
    "                       'Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced',\n",
    "                       'Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced',\n",
    "                       'Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced'],\n",
    "        'Time': [13.8, 15.6, 12.3, 13.1, 10.7, 11.3, 14.2, 14.9, 12.6, 13.7, 11.1, 11.9,\n",
    "                 15.2, 16.3, 13.5, 14.7, 12.1, 12.9, 14.8, 15.7, 12.9, 13.8, 11.5, 12.1,\n",
    "                 15.5, 16.1, 13.2, 14.3, 11.7, 12.2]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Conduct two-way ANOVA\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=df).fit()\n",
    "sm.stats.anova_lm(model, typ=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97531a2b-2fe9-499f-9165-6789c6276874",
   "metadata": {},
   "source": [
    "### Ans11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f35d4a-77a4-419f-8fb9-e5d75c9c8d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -3.03\n",
      "P-value: 0.003\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Generate some example data\n",
    "np.random.seed(123)\n",
    "control_scores = np.random.normal(75, 10, size=100)\n",
    "experimental_scores = np.random.normal(80, 10, size=100)\n",
    "\n",
    "# Conduct two-sample t-test\n",
    "t_stat, p_val = ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Report the results\n",
    "print(\"T-statistic: {:.2f}\".format(t_stat))\n",
    "print(\"P-value: {:.3f}\".format(p_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d919382-48ab-4010-bcf5-d8dff1f384ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental   4.5336 0.0028 1.5846 7.4826   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Create a data frame with the data\n",
    "data = {'Group': ['Control'] * 100 + ['Experimental'] * 100,\n",
    "        'Score': np.concatenate((control_scores, experimental_scores))}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Conduct Tukey's HSD test\n",
    "tukey_results = pairwise_tukeyhsd(df['Score'], df['Group'])\n",
    "\n",
    "# Report the results\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ac912-b427-4efa-a202-98c62fee41a2",
   "metadata": {},
   "source": [
    "### Ans12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52d11705-7145-48f5-aff6-6b4c5e728a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "store 47.6875 2.0000 58.0000 0.0000\n",
      "===================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "#generate sample data\n",
    "store_a_sales = np.random.normal(1000, 100, 30)\n",
    "store_b_sales = np.random.normal(1200, 150, 30)\n",
    "store_c_sales = np.random.normal(900, 120, 30)\n",
    "\n",
    "sales_df = pd.DataFrame({\n",
    "    'Store A': store_a_sales,\n",
    "    'Store B': store_b_sales,\n",
    "    'Store C': store_c_sales\n",
    "})\n",
    "\n",
    "sales_df_melted = pd.melt(sales_df.reset_index(), id_vars=['index'], value_vars=['Store A', 'Store B', 'Store C'])\n",
    "sales_df_melted.columns = ['day', 'store', 'sales']\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "rm_anova = AnovaRM(sales_df_melted, 'sales', 'day', within=['store'])\n",
    "res = rm_anova.fit()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2366e8c5-b947-4bfe-9acf-385afa1232d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
