{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## installation\n",
        "\n",
        "installation instructions here: https://pytorch.org ."
      ],
      "metadata": {
        "id": "mytG7jx6dXJS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BYxza-CFdOdV"
      },
      "outputs": [],
      "source": [
        "# Uncomment and run the appropriate command for your operating system, if required\n",
        "\n",
        "# Linux / Binder\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Windows\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# MacOS\n",
        "# !pip install numpy torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "dS4o4cRVda5l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors\n",
        "\n",
        "At its core, PyTorch is a library for processing tensors. A tensor is a number, vector, matrix, or any n-dimensional array. Let's create a tensor with a single number."
      ],
      "metadata": {
        "id": "x_VzWtYHdmGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number\n",
        "t1 = torch.tensor(4.)\n",
        "t1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mZFIgJtddZw",
        "outputId": "ab7e2911-4212-4187-82c3-f4e94dc37d40"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`4.` is a shorthand for `4.0`. It is used to indicate to Python (and PyTorch) that you want to create a floating-point number. We can verify this by checking the `dtype` attribute of our tensor."
      ],
      "metadata": {
        "id": "LBOprF7Vdqb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjFFndpFdng6",
        "outputId": "f5e8ba76-ff10-4cf8-87ba-d869ea00fdd4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector\n",
        "t2 = torch.tensor([1., 2, 3, 4])\n",
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riIuJoHIdtDY",
        "outputId": "09442a18-8a32-4b18-8435-283c095eb810"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix\n",
        "t3 = torch.tensor([[5.,6],\n",
        "                   [7,8],\n",
        "                   [9,10]])\n",
        "t3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nvw8-eFd96w",
        "outputId": "a5a79ea3-eb57-448b-d006-44354939d1b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3-dimensional array\n",
        "t4 = torch.tensor([\n",
        "    [[11, 12, 13],\n",
        "     [13, 14, 15]],\n",
        "    [[15, 16, 17],\n",
        "     [17, 18, 19.]]])\n",
        "t4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYfWdH2LeQMb",
        "outputId": "b94c9edd-23ba-4f5c-f36d-3c96ff7a1d5e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[11., 12., 13.],\n",
              "         [13., 14., 15.]],\n",
              "\n",
              "        [[15., 16., 17.],\n",
              "         [17., 18., 19.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors can have any number of dimensions and different lengths along each dimension. We can inspect the length along each dimension using the `.shape` property of a tensor."
      ],
      "metadata": {
        "id": "sfj_KWfZeV3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(t1)\n",
        "t1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGxwWXUfeTSS",
        "outputId": "abcd74e7-80a0-4b0d-9a05-1dfc2ee3024e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t2)\n",
        "t2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsafLvC_eXWL",
        "outputId": "15a72b42-b563-40ed-bf60-d06ce1acd611"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t3)\n",
        "t3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhSa04IieYaK",
        "outputId": "559f1c76-cc16-4b85-feb9-77c25a12a03a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t4)\n",
        "t4.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jBofuFOeZtq",
        "outputId": "21a2ebb9-354c-4aba-8d87-c955684cbb9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[11., 12., 13.],\n",
            "         [13., 14., 15.]],\n",
            "\n",
            "        [[15., 16., 17.],\n",
            "         [17., 18., 19.]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that it's not possible to create tensors with an improper shape."
      ],
      "metadata": {
        "id": "n1COT-Q1ejwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix\n",
        "t5 = torch.tensor([[5., 6, 11],\n",
        "                   [7, 8],\n",
        "                   [9, 10]])\n",
        "t5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "ljKCMFxBea1s",
        "outputId": "027ebef8-6955-4375-f303-9f599cada90d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-83912cf67c5e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m t5 = torch.tensor([[5., 6, 11], \n\u001b[0m\u001b[1;32m      3\u001b[0m                    \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    [9, 10]])\n\u001b[1;32m      5\u001b[0m \u001b[0mt5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 3 at dim 1 (got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor operations and gradients\n",
        "\n",
        "We can combine tensors with the usual arithmetic operations. Let's look at an example:"
      ],
      "metadata": {
        "id": "-oQGLw9yes2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A `ValueError` is thrown because the lengths of the rows `[5., 6, 11]` and `[7, 8]` don't match."
      ],
      "metadata": {
        "id": "k7vNrvTReobj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  # Create tensors.\n",
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True)\n",
        "b = torch.tensor(5., requires_grad=True)\n",
        "x, w, b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BptK8VNuelIb",
        "outputId": "83da946e-c9ad-4107-8de3-86282c43ceea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've created three tensors: `x`, `w`, and `b`, all numbers. `w` and `b` have an additional parameter `requires_grad` set to `True`. We'll see what it does in just a moment.\n",
        "\n",
        "Let's create a new tensor `y` by combining these tensors."
      ],
      "metadata": {
        "id": "3ixhrsf3eyz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Arithmetic operations\n",
        "y = w * x + b\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VQj7h9EewJw",
        "outputId": "04cd5ea1-9c83-4d5c-cd35-d1545b6f7da3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, `y` is a tensor with the value `3 * 4 + 5 = 17`. What makes PyTorch unique is that we can automatically compute the derivative of `y` w.r.t. the tensors that have `requires_grad` set to `True` i.e. w and b. This feature of PyTorch is called _autograd_ (automatic gradients).\n",
        "\n",
        "To compute the derivatives, we can invoke the `.backward` method on our result `y`."
      ],
      "metadata": {
        "id": "Ncb3OxF-e2LJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute derivatives\n",
        "y.backward()"
      ],
      "metadata": {
        "id": "IJ1Yg9Kpez-L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The derivatives of `y` with respect to the input tensors are stored in the `.grad` property of the respective tensors."
      ],
      "metadata": {
        "id": "NtT86N34e6pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display gradients\n",
        "print('dy/dx:', x.grad)\n",
        "print('dy/dw:', w.grad)\n",
        "print('dy/db:', b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shf29jLEe3YY",
        "outputId": "393ee299-3e0a-4721-b6cc-275085c3fb67"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx: None\n",
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, `dy/dw` has the same value as `x`, i.e., `3`, and `dy/db` has the value `1`. Note that `x.grad` is `None` because `x` doesn't have `requires_grad` set to `True`.\n",
        "\n",
        "The \"grad\" in `w.grad` is short for _gradient_, which is another term for derivative. The term _gradient_ is primarily used while dealing with vectors and matrices."
      ],
      "metadata": {
        "id": "d4Z-X3cGe-Q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor functions\n",
        "\n",
        "Apart from arithmetic operations, the `torch` module also contains many functions for creating and manipulating tensors. Let's look at some examples."
      ],
      "metadata": {
        "id": "0t-7gEfqfBeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with a fixed value for every element\n",
        "t6 = torch.full((3, 2), 42)\n",
        "t6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4u_W1Woe79J",
        "outputId": "a89e12a7-5690-477f-a556-5fba29e5acc9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42, 42],\n",
              "        [42, 42],\n",
              "        [42, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate two tensors with compatible shapes\n",
        "t7 = torch.cat((t3, t6))\n",
        "t7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9ZAasbnfDOs",
        "outputId": "3db66f92-3c8e-4958-eafc-db0186619b71"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.],\n",
              "        [42., 42.],\n",
              "        [42., 42.],\n",
              "        [42., 42.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Compute the sin of each element\n",
        "t8 = torch.sin(t7)\n",
        "t8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeVPwbVQfEmP",
        "outputId": "36fb4460-a57a-49e5-bdcc-72f9496f2129"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9589, -0.2794],\n",
              "        [ 0.6570,  0.9894],\n",
              "        [ 0.4121, -0.5440],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the shape of a tensor\n",
        "t9 = t8.reshape(3, 2, 2)\n",
        "t9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abfEWZxifGkp",
        "outputId": "28d05f22-fadc-4cb0-c123-d643606e43be"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9589, -0.2794],\n",
              "         [ 0.6570,  0.9894]],\n",
              "\n",
              "        [[ 0.4121, -0.5440],\n",
              "         [-0.9165, -0.9165]],\n",
              "\n",
              "        [[-0.9165, -0.9165],\n",
              "         [-0.9165, -0.9165]]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can learn more about tensor operations here: https://pytorch.org/docs/stable/torch.html . Experiment with some more tensor functions and operations using the empty cells below."
      ],
      "metadata": {
        "id": "-avm1qCKfKyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interoperability with Numpy\n",
        "\n",
        "[Numpy](http://www.numpy.org/) is a popular open-source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays and has a vast ecosystem of supporting libraries, including:\n",
        "\n",
        "* [Pandas](https://pandas.pydata.org/) for file I/O and data analysis\n",
        "* [Matplotlib](https://matplotlib.org/) for plotting and visualization\n",
        "* [OpenCV](https://opencv.org/) for image and video processing\n",
        "\n",
        "\n",
        "Instead of reinventing the wheel, PyTorch interoperates well with Numpy to leverage its existing ecosystem of tools and libraries."
      ],
      "metadata": {
        "id": "mySAYMxEfOxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's how we create an array in Numpy:"
      ],
      "metadata": {
        "id": "Gq6CRP8wfRYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([[1, 2], [3, 4.]])\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dKu_55QfH6n",
        "outputId": "1f28f9b4-8ebd-4818-8b0f-59448156f1bc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can convert a Numpy array to a PyTorch tensor using `torch.from_numpy`."
      ],
      "metadata": {
        "id": "XyWZ86fKfU0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the numpy array to a torch tensor.\n",
        "y = torch.from_numpy(x)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg8jKxOnfS44",
        "outputId": "23578ea8-7e5e-471b-899e-2038da3feec6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's verify that the numpy array and torch tensor have similar data types."
      ],
      "metadata": {
        "id": "2L4BbhKnfY3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.dtype, y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI-DeguHfWTI",
        "outputId": "b1bd5fae-3376-40ce-b84a-a000ed4da880"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float64'), torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert a torch tensor to a numpy array\n",
        "z = y.numpy()\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEI5oj5IfaMA",
        "outputId": "405fc88e-150c-4395-aa6d-0343de27c894"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The interoperability between PyTorch and Numpy is essential because most datasets you'll work with will likely be read and preprocessed as Numpy arrays.\n",
        "\n",
        "You might wonder why we need a library like PyTorch at all since Numpy already provides data structures and utilities for working with multi-dimensional numeric data. There are two main reasons:\n",
        "\n",
        "1. **Autograd**: The ability to automatically compute gradients for tensor operations is essential for training deep learning models.\n",
        "2. **GPU support**: While working with massive datasets and large models, PyTorch tensor operations can be performed efficiently using a Graphics Processing Unit (GPU). Computations that might typically take hours can be completed within minutes using GPUs.\n",
        "\n"
      ],
      "metadata": {
        "id": "wii75aiufeZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear-regression from scrach using pytorch"
      ],
      "metadata": {
        "id": "M-yA7MuEfict"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "1--f0_-AfbMf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making training data\n",
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')"
      ],
      "metadata": {
        "id": "LHnPvvUafj0q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Targets (apples, oranges)\n",
        "target = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119]], dtype='float32')"
      ],
      "metadata": {
        "id": "Q7eWtZUufk1E"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert input and target to tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "target = torch.from_numpy(target)\n",
        "\n",
        "print(inputs,\"\\n\")\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OXdml0Dfl3V",
        "outputId": "5ea679e6-0b61-4ffb-a0fa-94ca5f0448a4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]]) \n",
            "\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # weights and biases\n",
        "w = torch.randn(2,3 , requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPIJ__l5fm1g",
        "outputId": "a21059c5-7353-473c-aa00-7ef583c2b8f3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.9869, -0.3994, -1.4240],\n",
            "        [-0.7071,  0.5633,  1.4926]], requires_grad=True)\n",
            "tensor([-0.9238,  0.4101], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define the model\n",
        "\n",
        "def model(x):\n",
        "  return x @ w.t() + b"
      ],
      "metadata": {
        "id": "aD6EZVJJfomv"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9SXk5jEfqAT",
        "outputId": "df8cccbd-7885-4bae-f8a9-8edd581a1e95"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-16.8726,  50.7135],\n",
            "        [-37.4000,  81.1595],\n",
            "        [-51.1746, 100.9421],\n",
            "        [ 29.8759,   7.7336],\n",
            "        [-70.8504, 110.1776]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#actual\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym-2qW_LfrHi",
        "outputId": "f2853506-4a31-4e0b-a888-9875ef260819"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function MSE\n",
        "def MSE(actual, target):\n",
        "  diff = actual - target\n",
        "  return torch.sum(diff * diff) / diff.numel()"
      ],
      "metadata": {
        "id": "f1Rzx2eBfssu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# error\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPV598NWfuHW",
        "outputId": "d5c52409-ea7a-42ff-8db1-b763fba95258"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8130.2056, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # compute gradients\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "qAxM9zx7fvMD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w, \"\\n\")\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0wJgq3mfwTI",
        "outputId": "60748df7-660e-4646-bf71-d18d6cdae8b0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.9869, -0.3994, -1.4240],\n",
            "        [-0.7071,  0.5633,  1.4926]], requires_grad=True) \n",
            "\n",
            "tensor([[ -8418.3262, -10891.2080,  -6491.8745],\n",
            "        [ -1919.2699,  -1887.8640,  -1131.7783]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b, \"\\n\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evlOfvr3fxxH",
        "outputId": "8f0d1187-3417-4bee-e114-0e82de45a605"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.9238,  0.4101], requires_grad=True) \n",
            "\n",
            "tensor([-105.4843,  -21.8547])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reset grad\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP7WHfBCfzky",
        "outputId": "3f36150c-67a0-4781-e73c-aa6428ef3d65"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust params\n",
        "\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RknC8b6ygWc9",
        "outputId": "0d9f309b-1010-4c8f-84fe-fcc3ef2c8ec7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-16.8726,  50.7135],\n",
            "        [-37.4000,  81.1595],\n",
            "        [-51.1746, 100.9421],\n",
            "        [ 29.8759,   7.7336],\n",
            "        [-70.8504, 110.1776]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # loss\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNheHpZKgYnf",
        "outputId": "b1d27dde-fb5e-4931-fc36-57710ce022cb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8130.2056, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "\n",
        "print(w.grad, \"\\n\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNLoJuyYga7-",
        "outputId": "cf074470-e1c7-4bef-8b9a-144484ee6f5f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -8418.3262, -10891.2080,  -6491.8745],\n",
            "        [ -1919.2699,  -1887.8640,  -1131.7783]]) \n",
            "\n",
            "tensor([-105.4843,  -21.8547])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # adjust weight & reset grad\n",
        "with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ],
      "metadata": {
        "id": "dJrbwFLOgcGa"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_9OWCNdgdZ1",
        "outputId": "4d19c4c1-5401-4073-faba-ab865f91fc69"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0711, -0.2905, -1.3591],\n",
            "        [-0.6879,  0.5821,  1.5040]], requires_grad=True)\n",
            "tensor([-0.9228,  0.4103], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate again\n",
        "preds = model(inputs)\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vPwxF7qgfbt",
        "outputId": "00532141-b06d-4ad9-93f0-0702aec21f80"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5942.1074, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training for multiple epochs\n",
        "for i in range(400):\n",
        "  preds = model(inputs)\n",
        "  loss = MSE(target, preds)\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "     w -= w.grad * 1e-5 # learning rate\n",
        "     b -= b.grad * 1e-5\n",
        "     w.grad.zero_()\n",
        "     b.grad.zero_()\n",
        "  print(f\"Epochs({i}/{100}) & Loss {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnsZVHzOgh7i",
        "outputId": "4a01da71-1171-4d49-ce67-778ebf042183"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs(0/100) & Loss 5942.107421875\n",
            "Epochs(1/100) & Loss 4462.32568359375\n",
            "Epochs(2/100) & Loss 3459.93408203125\n",
            "Epochs(3/100) & Loss 2779.31298828125\n",
            "Epochs(4/100) & Loss 2315.591796875\n",
            "Epochs(5/100) & Loss 1998.098876953125\n",
            "Epochs(6/100) & Loss 1779.2086181640625\n",
            "Epochs(7/100) & Loss 1626.827392578125\n",
            "Epochs(8/100) & Loss 1519.326171875\n",
            "Epochs(9/100) & Loss 1442.12841796875\n",
            "Epochs(10/100) & Loss 1385.4100341796875\n",
            "Epochs(11/100) & Loss 1342.5513916015625\n",
            "Epochs(12/100) & Loss 1309.0902099609375\n",
            "Epochs(13/100) & Loss 1282.01806640625\n",
            "Epochs(14/100) & Loss 1259.307373046875\n",
            "Epochs(15/100) & Loss 1239.591064453125\n",
            "Epochs(16/100) & Loss 1221.948486328125\n",
            "Epochs(17/100) & Loss 1205.7557373046875\n",
            "Epochs(18/100) & Loss 1190.593994140625\n",
            "Epochs(19/100) & Loss 1176.179443359375\n",
            "Epochs(20/100) & Loss 1162.3204345703125\n",
            "Epochs(21/100) & Loss 1148.88720703125\n",
            "Epochs(22/100) & Loss 1135.791259765625\n",
            "Epochs(23/100) & Loss 1122.972900390625\n",
            "Epochs(24/100) & Loss 1110.390625\n",
            "Epochs(25/100) & Loss 1098.016357421875\n",
            "Epochs(26/100) & Loss 1085.830322265625\n",
            "Epochs(27/100) & Loss 1073.818603515625\n",
            "Epochs(28/100) & Loss 1061.9718017578125\n",
            "Epochs(29/100) & Loss 1050.281494140625\n",
            "Epochs(30/100) & Loss 1038.7430419921875\n",
            "Epochs(31/100) & Loss 1027.352294921875\n",
            "Epochs(32/100) & Loss 1016.1051635742188\n",
            "Epochs(33/100) & Loss 1004.9993286132812\n",
            "Epochs(34/100) & Loss 994.0314331054688\n",
            "Epochs(35/100) & Loss 983.2003173828125\n",
            "Epochs(36/100) & Loss 972.5037231445312\n",
            "Epochs(37/100) & Loss 961.9390869140625\n",
            "Epochs(38/100) & Loss 951.5047607421875\n",
            "Epochs(39/100) & Loss 941.1995849609375\n",
            "Epochs(40/100) & Loss 931.0216064453125\n",
            "Epochs(41/100) & Loss 920.96875\n",
            "Epochs(42/100) & Loss 911.0397338867188\n",
            "Epochs(43/100) & Loss 901.2330932617188\n",
            "Epochs(44/100) & Loss 891.5471801757812\n",
            "Epochs(45/100) & Loss 881.9802856445312\n",
            "Epochs(46/100) & Loss 872.5311279296875\n",
            "Epochs(47/100) & Loss 863.1983642578125\n",
            "Epochs(48/100) & Loss 853.9801025390625\n",
            "Epochs(49/100) & Loss 844.8748779296875\n",
            "Epochs(50/100) & Loss 835.8819580078125\n",
            "Epochs(51/100) & Loss 826.99951171875\n",
            "Epochs(52/100) & Loss 818.2258911132812\n",
            "Epochs(53/100) & Loss 809.56005859375\n",
            "Epochs(54/100) & Loss 801.0005493164062\n",
            "Epochs(55/100) & Loss 792.5457153320312\n",
            "Epochs(56/100) & Loss 784.1951293945312\n",
            "Epochs(57/100) & Loss 775.9464721679688\n",
            "Epochs(58/100) & Loss 767.7991943359375\n",
            "Epochs(59/100) & Loss 759.7515258789062\n",
            "Epochs(60/100) & Loss 751.802490234375\n",
            "Epochs(61/100) & Loss 743.9508056640625\n",
            "Epochs(62/100) & Loss 736.1951904296875\n",
            "Epochs(63/100) & Loss 728.5344848632812\n",
            "Epochs(64/100) & Loss 720.9674072265625\n",
            "Epochs(65/100) & Loss 713.4931640625\n",
            "Epochs(66/100) & Loss 706.10986328125\n",
            "Epochs(67/100) & Loss 698.8168334960938\n",
            "Epochs(68/100) & Loss 691.6131591796875\n",
            "Epochs(69/100) & Loss 684.4970092773438\n",
            "Epochs(70/100) & Loss 677.4680786132812\n",
            "Epochs(71/100) & Loss 670.5248413085938\n",
            "Epochs(72/100) & Loss 663.6660766601562\n",
            "Epochs(73/100) & Loss 656.8909912109375\n",
            "Epochs(74/100) & Loss 650.1984252929688\n",
            "Epochs(75/100) & Loss 643.5877685546875\n",
            "Epochs(76/100) & Loss 637.0572509765625\n",
            "Epochs(77/100) & Loss 630.6062622070312\n",
            "Epochs(78/100) & Loss 624.2340087890625\n",
            "Epochs(79/100) & Loss 617.9390869140625\n",
            "Epochs(80/100) & Loss 611.7205810546875\n",
            "Epochs(81/100) & Loss 605.5779418945312\n",
            "Epochs(82/100) & Loss 599.5097045898438\n",
            "Epochs(83/100) & Loss 593.51513671875\n",
            "Epochs(84/100) & Loss 587.5934448242188\n",
            "Epochs(85/100) & Loss 581.7437133789062\n",
            "Epochs(86/100) & Loss 575.9647216796875\n",
            "Epochs(87/100) & Loss 570.2559204101562\n",
            "Epochs(88/100) & Loss 564.6162109375\n",
            "Epochs(89/100) & Loss 559.0447998046875\n",
            "Epochs(90/100) & Loss 553.541015625\n",
            "Epochs(91/100) & Loss 548.1038208007812\n",
            "Epochs(92/100) & Loss 542.7322998046875\n",
            "Epochs(93/100) & Loss 537.4256591796875\n",
            "Epochs(94/100) & Loss 532.1832275390625\n",
            "Epochs(95/100) & Loss 527.0042114257812\n",
            "Epochs(96/100) & Loss 521.8875732421875\n",
            "Epochs(97/100) & Loss 516.832763671875\n",
            "Epochs(98/100) & Loss 511.8389587402344\n",
            "Epochs(99/100) & Loss 506.9054260253906\n",
            "Epochs(100/100) & Loss 502.0311584472656\n",
            "Epochs(101/100) & Loss 497.2158203125\n",
            "Epochs(102/100) & Loss 492.45819091796875\n",
            "Epochs(103/100) & Loss 487.75811767578125\n",
            "Epochs(104/100) & Loss 483.1144104003906\n",
            "Epochs(105/100) & Loss 478.52642822265625\n",
            "Epochs(106/100) & Loss 473.99371337890625\n",
            "Epochs(107/100) & Loss 469.5154724121094\n",
            "Epochs(108/100) & Loss 465.09100341796875\n",
            "Epochs(109/100) & Loss 460.71954345703125\n",
            "Epochs(110/100) & Loss 456.40032958984375\n",
            "Epochs(111/100) & Loss 452.13311767578125\n",
            "Epochs(112/100) & Loss 447.9169006347656\n",
            "Epochs(113/100) & Loss 443.75115966796875\n",
            "Epochs(114/100) & Loss 439.63519287109375\n",
            "Epochs(115/100) & Loss 435.5685119628906\n",
            "Epochs(116/100) & Loss 431.55035400390625\n",
            "Epochs(117/100) & Loss 427.5801696777344\n",
            "Epochs(118/100) & Loss 423.6576232910156\n",
            "Epochs(119/100) & Loss 419.781494140625\n",
            "Epochs(120/100) & Loss 415.9517517089844\n",
            "Epochs(121/100) & Loss 412.16778564453125\n",
            "Epochs(122/100) & Loss 408.4287414550781\n",
            "Epochs(123/100) & Loss 404.734130859375\n",
            "Epochs(124/100) & Loss 401.0834655761719\n",
            "Epochs(125/100) & Loss 397.4762268066406\n",
            "Epochs(126/100) & Loss 393.9117736816406\n",
            "Epochs(127/100) & Loss 390.3896179199219\n",
            "Epochs(128/100) & Loss 386.9093933105469\n",
            "Epochs(129/100) & Loss 383.4703674316406\n",
            "Epochs(130/100) & Loss 380.0719909667969\n",
            "Epochs(131/100) & Loss 376.71392822265625\n",
            "Epochs(132/100) & Loss 373.39556884765625\n",
            "Epochs(133/100) & Loss 370.1164855957031\n",
            "Epochs(134/100) & Loss 366.8759765625\n",
            "Epochs(135/100) & Loss 363.6739196777344\n",
            "Epochs(136/100) & Loss 360.5093688964844\n",
            "Epochs(137/100) & Loss 357.3824768066406\n",
            "Epochs(138/100) & Loss 354.2922058105469\n",
            "Epochs(139/100) & Loss 351.23846435546875\n",
            "Epochs(140/100) & Loss 348.2204895019531\n",
            "Epochs(141/100) & Loss 345.23797607421875\n",
            "Epochs(142/100) & Loss 342.29071044921875\n",
            "Epochs(143/100) & Loss 339.37786865234375\n",
            "Epochs(144/100) & Loss 336.4991760253906\n",
            "Epochs(145/100) & Loss 333.65423583984375\n",
            "Epochs(146/100) & Loss 330.84283447265625\n",
            "Epochs(147/100) & Loss 328.06402587890625\n",
            "Epochs(148/100) & Loss 325.31787109375\n",
            "Epochs(149/100) & Loss 322.60357666015625\n",
            "Epochs(150/100) & Loss 319.92132568359375\n",
            "Epochs(151/100) & Loss 317.2701110839844\n",
            "Epochs(152/100) & Loss 314.6498718261719\n",
            "Epochs(153/100) & Loss 312.0601501464844\n",
            "Epochs(154/100) & Loss 309.50048828125\n",
            "Epochs(155/100) & Loss 306.970703125\n",
            "Epochs(156/100) & Loss 304.4703063964844\n",
            "Epochs(157/100) & Loss 301.9986877441406\n",
            "Epochs(158/100) & Loss 299.5560302734375\n",
            "Epochs(159/100) & Loss 297.1414489746094\n",
            "Epochs(160/100) & Loss 294.7550354003906\n",
            "Epochs(161/100) & Loss 292.3960876464844\n",
            "Epochs(162/100) & Loss 290.06439208984375\n",
            "Epochs(163/100) & Loss 287.7596435546875\n",
            "Epochs(164/100) & Loss 285.4814453125\n",
            "Epochs(165/100) & Loss 283.2294921875\n",
            "Epochs(166/100) & Loss 281.0035095214844\n",
            "Epochs(167/100) & Loss 278.8031005859375\n",
            "Epochs(168/100) & Loss 276.62786865234375\n",
            "Epochs(169/100) & Loss 274.47784423828125\n",
            "Epochs(170/100) & Loss 272.35235595703125\n",
            "Epochs(171/100) & Loss 270.2511901855469\n",
            "Epochs(172/100) & Loss 268.17413330078125\n",
            "Epochs(173/100) & Loss 266.1207580566406\n",
            "Epochs(174/100) & Loss 264.0907897949219\n",
            "Epochs(175/100) & Loss 262.0841064453125\n",
            "Epochs(176/100) & Loss 260.10028076171875\n",
            "Epochs(177/100) & Loss 258.13897705078125\n",
            "Epochs(178/100) & Loss 256.20001220703125\n",
            "Epochs(179/100) & Loss 254.28311157226562\n",
            "Epochs(180/100) & Loss 252.38796997070312\n",
            "Epochs(181/100) & Loss 250.5142822265625\n",
            "Epochs(182/100) & Loss 248.66177368164062\n",
            "Epochs(183/100) & Loss 246.8302459716797\n",
            "Epochs(184/100) & Loss 245.01956176757812\n",
            "Epochs(185/100) & Loss 243.22909545898438\n",
            "Epochs(186/100) & Loss 241.45889282226562\n",
            "Epochs(187/100) & Loss 239.708740234375\n",
            "Epochs(188/100) & Loss 237.97811889648438\n",
            "Epochs(189/100) & Loss 236.2669219970703\n",
            "Epochs(190/100) & Loss 234.5751953125\n",
            "Epochs(191/100) & Loss 232.9021453857422\n",
            "Epochs(192/100) & Loss 231.24789428710938\n",
            "Epochs(193/100) & Loss 229.6123504638672\n",
            "Epochs(194/100) & Loss 227.99490356445312\n",
            "Epochs(195/100) & Loss 226.39547729492188\n",
            "Epochs(196/100) & Loss 224.8138427734375\n",
            "Epochs(197/100) & Loss 223.2499542236328\n",
            "Epochs(198/100) & Loss 221.703369140625\n",
            "Epochs(199/100) & Loss 220.17398071289062\n",
            "Epochs(200/100) & Loss 218.6614990234375\n",
            "Epochs(201/100) & Loss 217.1658172607422\n",
            "Epochs(202/100) & Loss 215.68655395507812\n",
            "Epochs(203/100) & Loss 214.2237548828125\n",
            "Epochs(204/100) & Loss 212.77700805664062\n",
            "Epochs(205/100) & Loss 211.3462371826172\n",
            "Epochs(206/100) & Loss 209.93115234375\n",
            "Epochs(207/100) & Loss 208.5316619873047\n",
            "Epochs(208/100) & Loss 207.1475067138672\n",
            "Epochs(209/100) & Loss 205.7784423828125\n",
            "Epochs(210/100) & Loss 204.42440795898438\n",
            "Epochs(211/100) & Loss 203.08522033691406\n",
            "Epochs(212/100) & Loss 201.7605438232422\n",
            "Epochs(213/100) & Loss 200.45042419433594\n",
            "Epochs(214/100) & Loss 199.15444946289062\n",
            "Epochs(215/100) & Loss 197.87246704101562\n",
            "Epochs(216/100) & Loss 196.6044464111328\n",
            "Epochs(217/100) & Loss 195.3502960205078\n",
            "Epochs(218/100) & Loss 194.1095428466797\n",
            "Epochs(219/100) & Loss 192.88230895996094\n",
            "Epochs(220/100) & Loss 191.6681671142578\n",
            "Epochs(221/100) & Loss 190.46710205078125\n",
            "Epochs(222/100) & Loss 189.27903747558594\n",
            "Epochs(223/100) & Loss 188.10369873046875\n",
            "Epochs(224/100) & Loss 186.94088745117188\n",
            "Epochs(225/100) & Loss 185.79049682617188\n",
            "Epochs(226/100) & Loss 184.65243530273438\n",
            "Epochs(227/100) & Loss 183.52645874023438\n",
            "Epochs(228/100) & Loss 182.41238403320312\n",
            "Epochs(229/100) & Loss 181.31036376953125\n",
            "Epochs(230/100) & Loss 180.21986389160156\n",
            "Epochs(231/100) & Loss 179.1409912109375\n",
            "Epochs(232/100) & Loss 178.07357788085938\n",
            "Epochs(233/100) & Loss 177.01719665527344\n",
            "Epochs(234/100) & Loss 175.9721221923828\n",
            "Epochs(235/100) & Loss 174.93804931640625\n",
            "Epochs(236/100) & Loss 173.91481018066406\n",
            "Epochs(237/100) & Loss 172.90216064453125\n",
            "Epochs(238/100) & Loss 171.90016174316406\n",
            "Epochs(239/100) & Loss 170.90878295898438\n",
            "Epochs(240/100) & Loss 169.9276123046875\n",
            "Epochs(241/100) & Loss 168.9566192626953\n",
            "Epochs(242/100) & Loss 167.99566650390625\n",
            "Epochs(243/100) & Loss 167.04476928710938\n",
            "Epochs(244/100) & Loss 166.10372924804688\n",
            "Epochs(245/100) & Loss 165.17233276367188\n",
            "Epochs(246/100) & Loss 164.25054931640625\n",
            "Epochs(247/100) & Loss 163.3382568359375\n",
            "Epochs(248/100) & Loss 162.435302734375\n",
            "Epochs(249/100) & Loss 161.5416259765625\n",
            "Epochs(250/100) & Loss 160.65716552734375\n",
            "Epochs(251/100) & Loss 159.7815704345703\n",
            "Epochs(252/100) & Loss 158.91502380371094\n",
            "Epochs(253/100) & Loss 158.0572052001953\n",
            "Epochs(254/100) & Loss 157.2080535888672\n",
            "Epochs(255/100) & Loss 156.36758422851562\n",
            "Epochs(256/100) & Loss 155.53562927246094\n",
            "Epochs(257/100) & Loss 154.71189880371094\n",
            "Epochs(258/100) & Loss 153.89659118652344\n",
            "Epochs(259/100) & Loss 153.0894012451172\n",
            "Epochs(260/100) & Loss 152.29037475585938\n",
            "Epochs(261/100) & Loss 151.49932861328125\n",
            "Epochs(262/100) & Loss 150.716064453125\n",
            "Epochs(263/100) & Loss 149.94064331054688\n",
            "Epochs(264/100) & Loss 149.1729278564453\n",
            "Epochs(265/100) & Loss 148.41290283203125\n",
            "Epochs(266/100) & Loss 147.66030883789062\n",
            "Epochs(267/100) & Loss 146.91513061523438\n",
            "Epochs(268/100) & Loss 146.17733764648438\n",
            "Epochs(269/100) & Loss 145.44674682617188\n",
            "Epochs(270/100) & Loss 144.7233123779297\n",
            "Epochs(271/100) & Loss 144.00697326660156\n",
            "Epochs(272/100) & Loss 143.2975616455078\n",
            "Epochs(273/100) & Loss 142.5950164794922\n",
            "Epochs(274/100) & Loss 141.89939880371094\n",
            "Epochs(275/100) & Loss 141.21041870117188\n",
            "Epochs(276/100) & Loss 140.5281982421875\n",
            "Epochs(277/100) & Loss 139.85252380371094\n",
            "Epochs(278/100) & Loss 139.183349609375\n",
            "Epochs(279/100) & Loss 138.52047729492188\n",
            "Epochs(280/100) & Loss 137.8640594482422\n",
            "Epochs(281/100) & Loss 137.2139434814453\n",
            "Epochs(282/100) & Loss 136.56993103027344\n",
            "Epochs(283/100) & Loss 135.93206787109375\n",
            "Epochs(284/100) & Loss 135.30018615722656\n",
            "Epochs(285/100) & Loss 134.67437744140625\n",
            "Epochs(286/100) & Loss 134.05430603027344\n",
            "Epochs(287/100) & Loss 133.44015502929688\n",
            "Epochs(288/100) & Loss 132.83169555664062\n",
            "Epochs(289/100) & Loss 132.22903442382812\n",
            "Epochs(290/100) & Loss 131.6318817138672\n",
            "Epochs(291/100) & Loss 131.04039001464844\n",
            "Epochs(292/100) & Loss 130.45431518554688\n",
            "Epochs(293/100) & Loss 129.87364196777344\n",
            "Epochs(294/100) & Loss 129.29832458496094\n",
            "Epochs(295/100) & Loss 128.72830200195312\n",
            "Epochs(296/100) & Loss 128.16354370117188\n",
            "Epochs(297/100) & Loss 127.6039047241211\n",
            "Epochs(298/100) & Loss 127.0494384765625\n",
            "Epochs(299/100) & Loss 126.4999771118164\n",
            "Epochs(300/100) & Loss 125.95550537109375\n",
            "Epochs(301/100) & Loss 125.41593170166016\n",
            "Epochs(302/100) & Loss 124.88126373291016\n",
            "Epochs(303/100) & Loss 124.35133361816406\n",
            "Epochs(304/100) & Loss 123.8261947631836\n",
            "Epochs(305/100) & Loss 123.30570220947266\n",
            "Epochs(306/100) & Loss 122.7898941040039\n",
            "Epochs(307/100) & Loss 122.27870178222656\n",
            "Epochs(308/100) & Loss 121.7719497680664\n",
            "Epochs(309/100) & Loss 121.26969146728516\n",
            "Epochs(310/100) & Loss 120.77192687988281\n",
            "Epochs(311/100) & Loss 120.27848815917969\n",
            "Epochs(312/100) & Loss 119.78939056396484\n",
            "Epochs(313/100) & Loss 119.30452728271484\n",
            "Epochs(314/100) & Loss 118.8238754272461\n",
            "Epochs(315/100) & Loss 118.34747314453125\n",
            "Epochs(316/100) & Loss 117.87506103515625\n",
            "Epochs(317/100) & Loss 117.40678405761719\n",
            "Epochs(318/100) & Loss 116.94248962402344\n",
            "Epochs(319/100) & Loss 116.48234558105469\n",
            "Epochs(320/100) & Loss 116.0259017944336\n",
            "Epochs(321/100) & Loss 115.57344055175781\n",
            "Epochs(322/100) & Loss 115.12479400634766\n",
            "Epochs(323/100) & Loss 114.67997741699219\n",
            "Epochs(324/100) & Loss 114.23884582519531\n",
            "Epochs(325/100) & Loss 113.80143737792969\n",
            "Epochs(326/100) & Loss 113.3676986694336\n",
            "Epochs(327/100) & Loss 112.9375\n",
            "Epochs(328/100) & Loss 112.5110855102539\n",
            "Epochs(329/100) & Loss 112.08796691894531\n",
            "Epochs(330/100) & Loss 111.6684341430664\n",
            "Epochs(331/100) & Loss 111.25244140625\n",
            "Epochs(332/100) & Loss 110.83979797363281\n",
            "Epochs(333/100) & Loss 110.43048095703125\n",
            "Epochs(334/100) & Loss 110.0245132446289\n",
            "Epochs(335/100) & Loss 109.6218490600586\n",
            "Epochs(336/100) & Loss 109.22249603271484\n",
            "Epochs(337/100) & Loss 108.82623291015625\n",
            "Epochs(338/100) & Loss 108.4332275390625\n",
            "Epochs(339/100) & Loss 108.04338073730469\n",
            "Epochs(340/100) & Loss 107.65669250488281\n",
            "Epochs(341/100) & Loss 107.2729263305664\n",
            "Epochs(342/100) & Loss 106.89228820800781\n",
            "Epochs(343/100) & Loss 106.5146484375\n",
            "Epochs(344/100) & Loss 106.1399917602539\n",
            "Epochs(345/100) & Loss 105.76827239990234\n",
            "Epochs(346/100) & Loss 105.3994140625\n",
            "Epochs(347/100) & Loss 105.03340148925781\n",
            "Epochs(348/100) & Loss 104.67022705078125\n",
            "Epochs(349/100) & Loss 104.30987548828125\n",
            "Epochs(350/100) & Loss 103.9522705078125\n",
            "Epochs(351/100) & Loss 103.59745025634766\n",
            "Epochs(352/100) & Loss 103.2453384399414\n",
            "Epochs(353/100) & Loss 102.89582824707031\n",
            "Epochs(354/100) & Loss 102.54898834228516\n",
            "Epochs(355/100) & Loss 102.20494079589844\n",
            "Epochs(356/100) & Loss 101.86326599121094\n",
            "Epochs(357/100) & Loss 101.52412414550781\n",
            "Epochs(358/100) & Loss 101.18755340576172\n",
            "Epochs(359/100) & Loss 100.85353088378906\n",
            "Epochs(360/100) & Loss 100.52196502685547\n",
            "Epochs(361/100) & Loss 100.19288635253906\n",
            "Epochs(362/100) & Loss 99.86616516113281\n",
            "Epochs(363/100) & Loss 99.54180908203125\n",
            "Epochs(364/100) & Loss 99.21983337402344\n",
            "Epochs(365/100) & Loss 98.900146484375\n",
            "Epochs(366/100) & Loss 98.582763671875\n",
            "Epochs(367/100) & Loss 98.267822265625\n",
            "Epochs(368/100) & Loss 97.95501708984375\n",
            "Epochs(369/100) & Loss 97.64440155029297\n",
            "Epochs(370/100) & Loss 97.33599853515625\n",
            "Epochs(371/100) & Loss 97.0299072265625\n",
            "Epochs(372/100) & Loss 96.72590637207031\n",
            "Epochs(373/100) & Loss 96.4240493774414\n",
            "Epochs(374/100) & Loss 96.12422943115234\n",
            "Epochs(375/100) & Loss 95.8265609741211\n",
            "Epochs(376/100) & Loss 95.53086853027344\n",
            "Epochs(377/100) & Loss 95.23731994628906\n",
            "Epochs(378/100) & Loss 94.94575500488281\n",
            "Epochs(379/100) & Loss 94.6561508178711\n",
            "Epochs(380/100) & Loss 94.36845397949219\n",
            "Epochs(381/100) & Loss 94.08283996582031\n",
            "Epochs(382/100) & Loss 93.79904174804688\n",
            "Epochs(383/100) & Loss 93.51729583740234\n",
            "Epochs(384/100) & Loss 93.23735809326172\n",
            "Epochs(385/100) & Loss 92.95927429199219\n",
            "Epochs(386/100) & Loss 92.68299865722656\n",
            "Epochs(387/100) & Loss 92.40861511230469\n",
            "Epochs(388/100) & Loss 92.13597869873047\n",
            "Epochs(389/100) & Loss 91.8651351928711\n",
            "Epochs(390/100) & Loss 91.5960693359375\n",
            "Epochs(391/100) & Loss 91.32884979248047\n",
            "Epochs(392/100) & Loss 91.0632553100586\n",
            "Epochs(393/100) & Loss 90.79940795898438\n",
            "Epochs(394/100) & Loss 90.53717041015625\n",
            "Epochs(395/100) & Loss 90.27666473388672\n",
            "Epochs(396/100) & Loss 90.01786804199219\n",
            "Epochs(397/100) & Loss 89.76065826416016\n",
            "Epochs(398/100) & Loss 89.50508117675781\n",
            "Epochs(399/100) & Loss 89.25105285644531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL5Tc75DgjPY",
        "outputId": "60d30b12-ce38-4d2e-f8b0-1e035abff0aa"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(88.9986, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "sqrt(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoAEq7CGgteS",
        "outputId": "85680aaa-0e98-4851-ad67-7c16253d7a60"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.433908347497573"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43qqqcn5gvLh",
        "outputId": "c5f01608-041d-469e-9377-c39c9eb78097"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 59.2467,  69.8648],\n",
              "        [ 74.9273, 103.8244],\n",
              "        [131.8999, 126.5003],\n",
              "        [ 33.2049,  34.3815],\n",
              "        [ 81.9989, 126.2431]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1m8kjSHgwrW",
        "outputId": "5828ea1b-083a-4563-9e92-0392b7109535"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## You can see they are almost close earch other"
      ],
      "metadata": {
        "id": "YDLFPl0HgxvU"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network using Pytorch"
      ],
      "metadata": {
        "id": "U5Npd_hSg003"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4LIhfdDjg2cW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81TjzKarg-1J",
        "outputId": "d515b8c4-0cd0-4a9a-a2ab-42f9adec640e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 26421880/26421880 [00:14<00:00, 1866750.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 29515/29515 [00:00<00:00, 136357.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 4422102/4422102 [00:01<00:00, 2477147.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 5148/5148 [00:00<00:00, 23885262.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaWaMnCHg_-M",
        "outputId": "68699274-f379-4636-bda5-12647b49d4cb"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.FashionMNIST"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    # print(X)\n",
        "    # print(y)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z4q_TvQhHhR",
        "outputId": "a927af91-6f26-46bd-f09e-a932b80633ed"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UOeCRV3hJmw",
        "outputId": "23adfda3-2bab-49a1-d04e-7726294abdfb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQWYqyCyhLFt",
        "outputId": "833ad5bf-6587-45b8-a902-574ef6fef2d1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "w9JrDBWlhMhe"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "KVimR42-hOjk"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "YRRL4AXIhQTt"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5be0ckXZhRcq",
        "outputId": "88d95e56-fa44-4999-c286-c456ddcfacaa"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.300568  [    0/60000]\n",
            "loss: 2.294092  [ 6400/60000]\n",
            "loss: 2.277620  [12800/60000]\n",
            "loss: 2.277789  [19200/60000]\n",
            "loss: 2.248350  [25600/60000]\n",
            "loss: 2.225376  [32000/60000]\n",
            "loss: 2.232074  [38400/60000]\n",
            "loss: 2.195417  [44800/60000]\n",
            "loss: 2.196385  [51200/60000]\n",
            "loss: 2.162493  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 43.5%, Avg loss: 2.165449 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.175286  [    0/60000]\n",
            "loss: 2.168028  [ 6400/60000]\n",
            "loss: 2.113466  [12800/60000]\n",
            "loss: 2.131112  [19200/60000]\n",
            "loss: 2.064315  [25600/60000]\n",
            "loss: 2.012563  [32000/60000]\n",
            "loss: 2.040306  [38400/60000]\n",
            "loss: 1.956064  [44800/60000]\n",
            "loss: 1.962467  [51200/60000]\n",
            "loss: 1.892064  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 50.4%, Avg loss: 1.895198 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.930159  [    0/60000]\n",
            "loss: 1.900386  [ 6400/60000]\n",
            "loss: 1.785848  [12800/60000]\n",
            "loss: 1.829207  [19200/60000]\n",
            "loss: 1.714321  [25600/60000]\n",
            "loss: 1.671116  [32000/60000]\n",
            "loss: 1.697269  [38400/60000]\n",
            "loss: 1.599257  [44800/60000]\n",
            "loss: 1.621781  [51200/60000]\n",
            "loss: 1.521587  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 59.6%, Avg loss: 1.542053 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.608767  [    0/60000]\n",
            "loss: 1.574562  [ 6400/60000]\n",
            "loss: 1.430674  [12800/60000]\n",
            "loss: 1.500116  [19200/60000]\n",
            "loss: 1.389600  [25600/60000]\n",
            "loss: 1.381409  [32000/60000]\n",
            "loss: 1.394247  [38400/60000]\n",
            "loss: 1.326268  [44800/60000]\n",
            "loss: 1.351635  [51200/60000]\n",
            "loss: 1.253391  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 62.6%, Avg loss: 1.283194 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.359370  [    0/60000]\n",
            "loss: 1.341793  [ 6400/60000]\n",
            "loss: 1.182199  [12800/60000]\n",
            "loss: 1.279700  [19200/60000]\n",
            "loss: 1.164905  [25600/60000]\n",
            "loss: 1.183745  [32000/60000]\n",
            "loss: 1.199642  [38400/60000]\n",
            "loss: 1.148510  [44800/60000]\n",
            "loss: 1.175412  [51200/60000]\n",
            "loss: 1.088227  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.6%, Avg loss: 1.114826 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CIJtexShTSF",
        "outputId": "63914657-14c4-42b9-e3e2-ccfff842c0db"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load model\n",
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbYRchSXhyYF",
        "outputId": "ce26eeac-0fd4-42b5-a821-7369c4c29882"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prediction\n",
        "\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALaCGsZEhzkZ",
        "outputId": "d6cc00d6-bfa3-4c93-e10b-2831f684c1d5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tZghb9R1h1Qa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}